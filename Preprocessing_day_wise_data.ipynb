{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* @Author: Sankar\n",
    "* @Date: 2021-05-13 07:52:25\n",
    "* @Last Modified by: Sankar\n",
    "* @Last Modified time: 2021-05-14 14:58:09\n",
    "* @Title : Preprocessing of daywise.csv  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 48.38916015625,
      "end_time": 1620978560535.893
     }
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>3</td><td>application_1620973165995_0007</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn1-practi.jqqmmjdy4o0erj3pjnxm0xjo5g.bx.internal.cloudapp.net:8088/proxy/application_1620973165995_0007/\">Link</a></td><td><a target=\"_blank\" href=\"http://wn0-practi.jqqmmjdy4o0erj3pjnxm0xjo5g.bx.internal.cloudapp.net:30060/node/containerlogs/container_e02_1620973165995_0007_01_000001/livy\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 59.143798828125,
      "end_time": 1620979619048.186
     }
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import UserDefinedFunction, col, isnan, when, col, count, isnull, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 1295.941162109375,
      "end_time": 1620979629323.702
     }
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark_df = spark.read.csv('wasbs://hadoopcluster@mydemostorage1234.blob.core.windows.net/raw_input/day_wise.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 2274.0849609375,
      "end_time": 1620979634945.304
     }
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[summary: string, Confirmed: string, Deaths: string, Recovered: string, Active: string, New cases: string, New deaths: string, New recovered: string, Deaths / 100 Cases: string, Recovered / 100 Cases: string, Deaths / 100 Recovered: string, No. of countries: string]"
     ]
    }
   ],
   "source": [
    "spark_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 39.4609375,
      "end_time": 1620979635839.378
     }
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Confirmed: integer (nullable = true)\n",
      " |-- Deaths: integer (nullable = true)\n",
      " |-- Recovered: integer (nullable = true)\n",
      " |-- Active: integer (nullable = true)\n",
      " |-- New cases: integer (nullable = true)\n",
      " |-- New deaths: integer (nullable = true)\n",
      " |-- New recovered: integer (nullable = true)\n",
      " |-- Deaths / 100 Cases: double (nullable = true)\n",
      " |-- Recovered / 100 Cases: double (nullable = true)\n",
      " |-- Deaths / 100 Recovered: double (nullable = true)\n",
      " |-- No. of countries: integer (nullable = true)"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 761.074951171875,
      "end_time": 1620979640073.461
     }
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(Date=datetime.datetime(2020, 1, 22, 0, 0), Confirmed=555, Deaths=17, Recovered=28, Active=510, New cases=0, New deaths=0, New recovered=0, Deaths / 100 Cases=3.06, Recovered / 100 Cases=5.05, Deaths / 100 Recovered=60.71, No. of countries=6), Row(Date=datetime.datetime(2020, 1, 23, 0, 0), Confirmed=654, Deaths=18, Recovered=30, Active=606, New cases=99, New deaths=1, New recovered=2, Deaths / 100 Cases=2.75, Recovered / 100 Cases=4.59, Deaths / 100 Recovered=60.0, No. of countries=8), Row(Date=datetime.datetime(2020, 1, 24, 0, 0), Confirmed=941, Deaths=26, Recovered=36, Active=879, New cases=287, New deaths=8, New recovered=6, Deaths / 100 Cases=2.76, Recovered / 100 Cases=3.83, Deaths / 100 Recovered=72.22, No. of countries=9), Row(Date=datetime.datetime(2020, 1, 25, 0, 0), Confirmed=1434, Deaths=42, Recovered=39, Active=1353, New cases=493, New deaths=16, New recovered=3, Deaths / 100 Cases=2.93, Recovered / 100 Cases=2.72, Deaths / 100 Recovered=107.69, No. of countries=11), Row(Date=datetime.datetime(2020, 1, 26, 0, 0), Confirmed=2118, Deaths=56, Recovered=52, Active=2010, New cases=684, New deaths=14, New recovered=13, Deaths / 100 Cases=2.64, Recovered / 100 Cases=2.46, Deaths / 100 Recovered=107.69, No. of countries=13)]"
     ]
    }
   ],
   "source": [
    "spark_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 52.06201171875,
      "end_time": 1620978609470.922
     }
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Helper function to drop unused columns and rename interesting columns.\n",
    "def selectInterestingColumns(rawDf):\n",
    "    # Mapping column index to name.\n",
    "    columnNames = {0: \"DateDayWise\", 1:\"ConfirmedCases\", 2:\"ConfirmedDeaths\", 3:\"RecoveredCases\"} \n",
    "    # Rename column from 'data' to something meaningful\n",
    "    cols = [col(rawDf.columns[i]).alias(columnNames[i]) for i in columnNames.keys()]\n",
    "    \n",
    "    # Drop columns we are not using.\n",
    "    df = rawDf.select(cols)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 5416.490966796875,
      "end_time": 1620978627070.913
     }
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188"
     ]
    }
   ],
   "source": [
    "df = selectInterestingColumns(spark_df).cache()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 35.829833984375,
      "end_time": 1620978629023.143
     }
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DateDayWise: timestamp (nullable = true)\n",
      " |-- ConfirmedCases: integer (nullable = true)\n",
      " |-- ConfirmedDeaths: integer (nullable = true)\n",
      " |-- RecoveredCases: integer (nullable = true)"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 1881.8759765625,
      "end_time": 1620978632915.297
     }
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+---------------+--------------+\n",
      "|DateDayWise|ConfirmedCases|ConfirmedDeaths|RecoveredCases|\n",
      "+-----------+--------------+---------------+--------------+\n",
      "|          0|             0|              0|             0|\n",
      "+-----------+--------------+---------------+--------------+"
     ]
    }
   ],
   "source": [
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 749.14111328125,
      "end_time": 1620978636217.339
     }
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+---------------+--------------+\n",
      "|        DateDayWise|ConfirmedCases|ConfirmedDeaths|RecoveredCases|\n",
      "+-------------------+--------------+---------------+--------------+\n",
      "|2020-01-22 00:00:00|           555|             17|            28|\n",
      "|2020-01-23 00:00:00|           654|             18|            30|\n",
      "|2020-01-24 00:00:00|           941|             26|            36|\n",
      "|2020-01-25 00:00:00|          1434|             42|            39|\n",
      "|2020-01-26 00:00:00|          2118|             56|            52|\n",
      "|2020-01-27 00:00:00|          2927|             82|            61|\n",
      "|2020-01-28 00:00:00|          5578|            131|           107|\n",
      "|2020-01-29 00:00:00|          6166|            133|           125|\n",
      "|2020-01-30 00:00:00|          8234|            171|           141|\n",
      "|2020-01-31 00:00:00|          9927|            213|           219|\n",
      "|2020-02-01 00:00:00|         12038|            259|           281|\n",
      "|2020-02-02 00:00:00|         16787|            362|           459|\n",
      "|2020-02-03 00:00:00|         19887|            426|           604|\n",
      "|2020-02-04 00:00:00|         23898|            492|           821|\n",
      "|2020-02-05 00:00:00|         27643|            564|          1071|\n",
      "|2020-02-06 00:00:00|         30802|            634|          1418|\n",
      "|2020-02-07 00:00:00|         34334|            719|          1903|\n",
      "|2020-02-08 00:00:00|         37068|            806|          2470|\n",
      "|2020-02-09 00:00:00|         40095|            906|          3057|\n",
      "|2020-02-10 00:00:00|         42633|           1013|          3714|\n",
      "+-------------------+--------------+---------------+--------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 2276.736083984375,
      "end_time": 1620978667138.683
     }
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.write.csv('wasbs://hadoopcluster@mydemostorage1234.blob.core.windows.net/processed_ouput/day_wise_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 19401.385009765625,
      "end_time": 1620966697067.47
     }
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.write.saveAsTable(\"hvdaywise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}