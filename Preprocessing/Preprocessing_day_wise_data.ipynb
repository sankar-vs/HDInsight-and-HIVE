{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* @Author: Sankar\n",
    "* @Date: 2021-05-13 07:52:25\n",
    "* @Last Modified by: Sankar\n",
    "* @Last Modified time: 2021-05-14 19:58:09\n",
    "* @Title : Preprocessing of daywise.csv  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 34.2900390625,
      "end_time": 1620995981693.419
     }
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>6</td><td>application_1620973165995_0020</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn1-practi.jqqmmjdy4o0erj3pjnxm0xjo5g.bx.internal.cloudapp.net:8088/proxy/application_1620973165995_0020/\">Link</a></td><td><a target=\"_blank\" href=\"http://wn1-practi.jqqmmjdy4o0erj3pjnxm0xjo5g.bx.internal.cloudapp.net:30060/node/containerlogs/container_e02_1620973165995_0020_01_000001/livy\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 295.27294921875,
      "end_time": 1620995991416.194
     }
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import UserDefinedFunction, col, isnan, when, col, count, isnull, mean, to_date, to_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 7416.369873046875,
      "end_time": 1620996001070.547
     }
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark_df = spark.read.csv('wasbs://hadoopcluster@mydemostorage1234.blob.core.windows.net/raw_input/day_wise.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 7307.85986328125,
      "end_time": 1620996011572.566
     }
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[summary: string, Confirmed: string, Deaths: string, Recovered: string, Active: string, New cases: string, New deaths: string, New recovered: string, Deaths / 100 Cases: string, Recovered / 100 Cases: string, Deaths / 100 Recovered: string, No. of countries: string]"
     ]
    }
   ],
   "source": [
    "spark_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 36.77392578125,
      "end_time": 1620996013810.123
     }
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Confirmed: integer (nullable = true)\n",
      " |-- Deaths: integer (nullable = true)\n",
      " |-- Recovered: integer (nullable = true)\n",
      " |-- Active: integer (nullable = true)\n",
      " |-- New cases: integer (nullable = true)\n",
      " |-- New deaths: integer (nullable = true)\n",
      " |-- New recovered: integer (nullable = true)\n",
      " |-- Deaths / 100 Cases: double (nullable = true)\n",
      " |-- Recovered / 100 Cases: double (nullable = true)\n",
      " |-- Deaths / 100 Recovered: double (nullable = true)\n",
      " |-- No. of countries: integer (nullable = true)"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 743.6240234375,
      "end_time": 1620996017273.548
     }
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(Date=datetime.datetime(2020, 1, 22, 0, 0), Confirmed=555, Deaths=17, Recovered=28, Active=510, New cases=0, New deaths=0, New recovered=0, Deaths / 100 Cases=3.06, Recovered / 100 Cases=5.05, Deaths / 100 Recovered=60.71, No. of countries=6), Row(Date=datetime.datetime(2020, 1, 23, 0, 0), Confirmed=654, Deaths=18, Recovered=30, Active=606, New cases=99, New deaths=1, New recovered=2, Deaths / 100 Cases=2.75, Recovered / 100 Cases=4.59, Deaths / 100 Recovered=60.0, No. of countries=8), Row(Date=datetime.datetime(2020, 1, 24, 0, 0), Confirmed=941, Deaths=26, Recovered=36, Active=879, New cases=287, New deaths=8, New recovered=6, Deaths / 100 Cases=2.76, Recovered / 100 Cases=3.83, Deaths / 100 Recovered=72.22, No. of countries=9), Row(Date=datetime.datetime(2020, 1, 25, 0, 0), Confirmed=1434, Deaths=42, Recovered=39, Active=1353, New cases=493, New deaths=16, New recovered=3, Deaths / 100 Cases=2.93, Recovered / 100 Cases=2.72, Deaths / 100 Recovered=107.69, No. of countries=11), Row(Date=datetime.datetime(2020, 1, 26, 0, 0), Confirmed=2118, Deaths=56, Recovered=52, Active=2010, New cases=684, New deaths=14, New recovered=13, Deaths / 100 Cases=2.64, Recovered / 100 Cases=2.46, Deaths / 100 Recovered=107.69, No. of countries=13)]"
     ]
    }
   ],
   "source": [
    "spark_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 255.344970703125,
      "end_time": 1620996019379.967
     }
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Converting Date:TIMESTAMP column to DateDayWise:DATE \n",
    "# spark_df.select(to_date(\"Date\", \"yyyy-MM-dd\").alias(\"DateDayWise\"))\n",
    "df_conv = spark_df.withColumn(\"DateDayWise\",to_date(col(\"Date\"),\"yyyy-MM-dd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 62.39697265625,
      "end_time": 1620996024151.873
     }
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Confirmed: integer (nullable = true)\n",
      " |-- Deaths: integer (nullable = true)\n",
      " |-- Recovered: integer (nullable = true)\n",
      " |-- Active: integer (nullable = true)\n",
      " |-- New cases: integer (nullable = true)\n",
      " |-- New deaths: integer (nullable = true)\n",
      " |-- New recovered: integer (nullable = true)\n",
      " |-- Deaths / 100 Cases: double (nullable = true)\n",
      " |-- Recovered / 100 Cases: double (nullable = true)\n",
      " |-- Deaths / 100 Recovered: double (nullable = true)\n",
      " |-- No. of countries: integer (nullable = true)\n",
      " |-- DateDayWise: date (nullable = true)"
     ]
    }
   ],
   "source": [
    "df_conv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 33.281982421875,
      "end_time": 1620996027702.067
     }
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Helper function to drop unused columns and rename interesting columns.\n",
    "def selectInterestingColumns(rawDf):\n",
    "    # Mapping column index to name.\n",
    "    columnNames = {12: \"DateDayWise\", 1:\"ConfirmedCases\", 2:\"ConfirmedDeaths\", 3:\"RecoveredCases\"} \n",
    "    # Rename column from 'data' to something meaningful\n",
    "    cols = [col(rawDf.columns[i]).alias(columnNames[i]) for i in columnNames.keys()]\n",
    "    \n",
    "    # Drop columns we are not using.\n",
    "    df = rawDf.select(cols)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 1258.486083984375,
      "end_time": 1620996100298.839
     }
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188"
     ]
    }
   ],
   "source": [
    "df = selectInterestingColumns(df_conv).cache()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 74.178955078125,
      "end_time": 1620996143423.789
     }
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ConfirmedCases: integer (nullable = true)\n",
      " |-- ConfirmedDeaths: integer (nullable = true)\n",
      " |-- RecoveredCases: integer (nullable = true)\n",
      " |-- DateDayWise: date (nullable = true)"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 247.615966796875,
      "end_time": 1620996184134.783
     }
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Changing the column position\n",
    "df = df.select(df.DateDayWise, df.ConfirmedCases, df.ConfirmedDeaths, df.RecoveredCases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 41.64404296875,
      "end_time": 1620996185874.346
     }
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DateDayWise: date (nullable = true)\n",
      " |-- ConfirmedCases: integer (nullable = true)\n",
      " |-- ConfirmedDeaths: integer (nullable = true)\n",
      " |-- RecoveredCases: integer (nullable = true)"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 761.218994140625,
      "end_time": 1620996197871.249
     }
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+---------------+--------------+\n",
      "|DateDayWise|ConfirmedCases|ConfirmedDeaths|RecoveredCases|\n",
      "+-----------+--------------+---------------+--------------+\n",
      "|          0|             0|              0|             0|\n",
      "+-----------+--------------+---------------+--------------+"
     ]
    }
   ],
   "source": [
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 769.19384765625,
      "end_time": 1620996200854.836
     }
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+---------------+--------------+\n",
      "|DateDayWise|ConfirmedCases|ConfirmedDeaths|RecoveredCases|\n",
      "+-----------+--------------+---------------+--------------+\n",
      "| 2020-01-22|           555|             17|            28|\n",
      "| 2020-01-23|           654|             18|            30|\n",
      "| 2020-01-24|           941|             26|            36|\n",
      "| 2020-01-25|          1434|             42|            39|\n",
      "| 2020-01-26|          2118|             56|            52|\n",
      "| 2020-01-27|          2927|             82|            61|\n",
      "| 2020-01-28|          5578|            131|           107|\n",
      "| 2020-01-29|          6166|            133|           125|\n",
      "| 2020-01-30|          8234|            171|           141|\n",
      "| 2020-01-31|          9927|            213|           219|\n",
      "| 2020-02-01|         12038|            259|           281|\n",
      "| 2020-02-02|         16787|            362|           459|\n",
      "| 2020-02-03|         19887|            426|           604|\n",
      "| 2020-02-04|         23898|            492|           821|\n",
      "| 2020-02-05|         27643|            564|          1071|\n",
      "| 2020-02-06|         30802|            634|          1418|\n",
      "| 2020-02-07|         34334|            719|          1903|\n",
      "| 2020-02-08|         37068|            806|          2470|\n",
      "| 2020-02-09|         40095|            906|          3057|\n",
      "| 2020-02-10|         42633|           1013|          3714|\n",
      "+-----------+--------------+---------------+--------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 2303.369873046875,
      "end_time": 1620996213441.985
     }
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.write.csv('wasbs://hadoopcluster@mydemostorage1234.blob.core.windows.net/processed/day_wise.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 9318.597900390625,
      "end_time": 1620996232919.753
     }
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.write.saveAsTable(\"hvdwise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}